#最新版本的learn2learn 解压的.tgz文件 .tgz数据文件是TMU RGB-D 数据集
# TMU- RGB-D:https://cvg.cit.tum.de/data/datasets/rgbd-dataset

!pip install learn2learn
import os
import tarfile
from google.colab import drive

import os
import tarfile

# 创建解压目录
extract_dir = '/content/dataset'
os.makedirs(extract_dir, exist_ok=True)

# 解压第一个数据集
dataset_path_1 = '/content/drive/MyDrive/rgbd_dataset_freiburg1_rpy.tgz'
tar_dir_1 = os.path.join(extract_dir, 'rgbd_dataset_freiburg1_rpy')
os.makedirs(tar_dir_1, exist_ok=True)
with tarfile.open(dataset_path_1, 'r:gz') as tar:
    tar.extractall(tar_dir_1)

# 解压第二个数据集
dataset_path_2 = '/content/drive/MyDrive/rgbd_dataset_freiburg1_xyz.tgz'
tar_dir_2 = os.path.join(extract_dir, 'rgbd_dataset_freiburg1_xyz')
os.makedirs(tar_dir_2, exist_ok=True)
with tarfile.open(dataset_path_2, 'r:gz') as tar:
    tar.extractall(tar_dir_2)


import os
import random
import tarfile
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from learn2learn.algorithms import MAML

# 数据集类定义
class RGBDSceneSegmentationDataset(Dataset):
    def __init__(self, dataset_paths, mode='train', test_ratio=0.2):
        self.rgb_paths = []
        self.depth_paths = []
        self.transform = transforms.Compose([
            transforms.Resize((128, 128)),
            transforms.ToTensor()
        ])
        self.mode = mode

        for dataset_path in dataset_paths:
            with tarfile.open(dataset_path, 'r') as tar:
                tar.extractall(path='/tmp/dataset/')
                extracted_path = os.path.join('/tmp/dataset', os.path.splitext(os.path.basename(dataset_path))[0])
                rgb_dir = os.path.join(extracted_path, 'rgb')
                depth_dir = os.path.join(extracted_path, 'depth')

                rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith(('.png', '.jpg'))])
                depth_files = sorted([f for f in os.listdir(depth_dir) if f.endswith(('.png', '.jpg'))])

                min_length = min(len(rgb_files), len(depth_files))
                rgb_files = rgb_files[:min_length]
                depth_files = depth_files[:min_length]

                for rgb_file, depth_file in zip(rgb_files, depth_files):
                    self.rgb_paths.append(os.path.join(rgb_dir, rgb_file))
                    self.depth_paths.append(os.path.join(depth_dir, depth_file))

        indices = list(range(len(self.rgb_paths)))
        split = int(np.floor(test_ratio * len(self.rgb_paths)))
        if mode == 'train':
            self.indices = indices[split:]
        else:
            self.indices = indices[:split]

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        actual_idx = self.indices[idx]
        rgb_path = self.rgb_paths[actual_idx]
        depth_path = self.depth_paths[actual_idx]

        rgb_img = Image.open(rgb_path).convert('RGB')
        depth_img = Image.open(depth_path).convert('L')

        rgb_tensor = self.transform(rgb_img)
        depth_tensor = self.transform(depth_img)

        return rgb_tensor, depth_tensor

# 任务采样函数
def sample_tasks(dataset, num_tasks, num_support, num_query):
    tasks = []
    for _ in range(num_tasks):
        indices = random.sample(range(len(dataset)), num_support + num_query)
        support_indices = indices[:num_support]
        query_indices = indices[num_support:]
        support_data = [(dataset[i][0], dataset[i][1]) for i in support_indices]
        query_data = [(dataset[i][0], dataset[i][1]) for i in query_indices]
        tasks.append((support_data, query_data))
    return tasks

# 语义分割模型定义
class SceneSegmentationModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(4, 4, kernel_size=3, stride=2, padding=1)
        self.bn1 = nn.BatchNorm2d(4)
        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1)
        self.bn2 = nn.BatchNorm2d(8)
        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1)
        self.bn3 = nn.BatchNorm2d(16)
        self.fc1 = nn.Linear(16 * 16 * 16, 32)
        self.fc2 = nn.Linear(32, 16)
        self.fc3 = nn.Linear(16, 2)

    def forward(self, rgb, depth):
        x = torch.cat([rgb, depth], dim=1)
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.relu(self.bn3(self.conv3(x)))
        x = x.view(-1, 16 * 16 * 16)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# MAML封装类定义
class MAMLWrapper:
    def __init__(self, model, lr=1e-3):
        self.maml = MAML(model, lr=lr, first_order=True)

    def __call__(self, support_data, query_data):
        support_tensors = [torch.stack([data[i] for data in support_data]) for i in range(2)]
        query_tensors = [torch.stack([data[i] for data in query_data]) for i in range(2)]

        support_labels = torch.zeros(len(support_tensors[0]), dtype=torch.long)
        query_labels = torch.zeros(len(query_tensors[0]), dtype=torch.long)

        support_preds = self.maml.module(support_tensors[0], support_tensors[1])
        query_preds = self.maml.module(query_tensors[0], query_tensors[1])

        support_loss = F.cross_entropy(support_preds, support_labels)
        query_loss = F.cross_entropy(query_preds, query_labels)

        self.maml.adapt(support_loss)

        return query_loss

# 加载数据集
dataset_paths = [
    '/content/drive/MyDrive/rgbd_dataset_freiburg1_rpy.tgz',
    '/content/drive/MyDrive/rgbd_dataset_freiburg1_xyz.tgz'
]
meta_train_dataset = RGBDSceneSegmentationDataset(dataset_paths, mode='train')
meta_test_dataset = RGBDSceneSegmentationDataset(dataset_paths, mode='test')

# 定义模型和元学习算法
model = SceneSegmentationModel()
maml_wrapper = MAMLWrapper(model, lr=1e-3)

# 调整训练过程
num_epochs = 100
num_tasks_per_epoch = 16
num_support = 5
num_query = 10

for epoch in range(num_epochs):
    epoch_loss = 0.0

    tasks = sample_tasks(meta_train_dataset, num_tasks_per_epoch, num_support, num_query)

    for support_data, query_data in tasks:
        query_loss = maml_wrapper(support_data, query_data)
        epoch_loss += query_loss.item()

    avg_loss = epoch_loss / num_tasks_per_epoch
    print(f'Epoch {epoch+1} | Average Loss: {avg_loss:.4f}')

# 测试过程
test_tasks = sample_tasks(meta_test_dataset, num_tasks_per_epoch, num_support, num_query)
test_accuracies = []

for support_data, query_data in test_tasks:
    support_tensors = [torch.stack([data[i] for data in support_data]) for i in range(2)]
    query_tensors = [torch.stack([data[i] for data in query_data]) for i in range(2)]

    support_labels = torch.zeros(len(support_tensors[0]), dtype=torch.long)
    query_labels = torch.zeros(len(query_tensors[0]), dtype=torch.long)

    maml_wrapper.maml.module.eval()
    with torch.no_grad():
        query_preds = model(query_tensors[0], query_tensors[1])
        query_accuracy = (query_preds.argmax(dim=1) == query_labels).float().mean().item()
        test_accuracies.append(query_accuracy)

final_test_accuracy = sum(test_accuracies) / len(test_accuracies)
print(f"Final test accuracy: {final_test_accuracy * 100:.2f}%")

